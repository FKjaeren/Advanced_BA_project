{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Report\n",
    "## Data preparation\n",
    "Data and preprocessing:\n",
    "In this project we will use two datasets. The first dataset contains ratings for groceries and gourmet foods and the second contains relevant information of the products. Both datasets are loaded with a function we call \"CreateData\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### Import raw data\n",
    "def load_data(rating_filepath, review_filepath, metadata_filepath):\n",
    "    ratings_df = pd.read_csv(rating_filepath, names = ['item','user','rating','timestamp'])\n",
    "    reviews_df = pd.read_json(review_filepath, lines=True)\n",
    "    metadata_df = pd.read_json(metadata_filepath, lines=True)\n",
    "    return ratings_df, reviews_df, metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a preparation of the data is performed with the function \"prepare_data\". The purpose of this function is to merge the datasets and to structure the data. In the function we group on each item and we find the average rating, standard deviation of rating and the number of ratings for each item. \n",
    "The \"category\" feature is changed so it only contains the first category of a list instead of a list with multiple categories.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### Function for preparing the data\n",
    "def prepare_data(ratings_df, reviews_df, metadata_df):\n",
    "    # create timestamps\n",
    "    ratings_df['timestamp'] = pd.to_datetime(ratings_df['timestamp'], origin = 'unix', unit = 's')\n",
    "    reviews_df['timestamp'] = pd.to_datetime(reviews_df['unixReviewTime'], origin = 'unix', unit = 's')\n",
    "    metadata_df['timestamp'] = pd.to_datetime(metadata_df['date'].apply(str), format = '%B %d, %Y', errors='coerce')\n",
    "\n",
    "    # drop columns in reviews\n",
    "    reviews_df = reviews_df.drop(columns=['unixReviewTime','reviewTime','reviewerName','vote','image','style','verified'])\n",
    "\n",
    "    # drop columns in metadata\n",
    "    metadata_df = metadata_df.drop(columns=['imageURL','imageURLHighRes'])\n",
    "    \n",
    "    # drop na's and duplicates\n",
    "    reviews_df = reviews_df.dropna()\n",
    "    reviews_df = reviews_df.drop_duplicates(keep='first')\n",
    "    ratings_df = ratings_df.drop_duplicates(keep='first')\n",
    "\n",
    "    # group ratings_df and merge with metadata, so there is one dataframe with both ratings and information of products\n",
    "    grouped_ratings = ratings_df[['item','rating']].groupby(by='item').agg({'rating':['mean','std'],'item':'size'}).rename(columns={'statistics':'avg_rating','item':'num_ratings'}).reset_index()\n",
    "    grouped_ratings.columns = ['_'.join(col).strip() if col[1] else col[0] for col in grouped_ratings.columns.values]\n",
    "    grouped_ratings = grouped_ratings.rename(columns = {'rating_mean':'avg_rating','rating_std':'std_rating','num_ratings_size':'num_ratings'})\n",
    "    metadata_df = grouped_ratings.merge(metadata_df, how='outer', left_on='item', right_on='asin')\n",
    "    metadata_df['item'].fillna(metadata_df['asin'], inplace=True)\n",
    "    metadata_df = metadata_df.drop(columns=['asin','date','tech1','tech2','fit'])\n",
    "\n",
    "    # preprocess price\n",
    "    metadata_df['price'] =  pd.to_numeric(metadata_df['price'].str.replace('$',''), errors='coerce')\n",
    "\n",
    "    # Fill nan with empty space and use the get_category function\n",
    "    metadata_df['category'] = metadata_df['category'].fillna('')\n",
    "    metadata_df['category'] = metadata_df['category'].apply(get_category)\n",
    "    \n",
    "\n",
    "    return reviews_df, metadata_df\n",
    "\n",
    "# Function to return only the first name in each category variable.\n",
    "def get_category(row):\n",
    "    if len(row) > 1:\n",
    "        category = row[1]\n",
    "    else:\n",
    "        category = row\n",
    "    return category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data is merged we save it as a new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rating_filepath = 'raw_data/Grocery_and_Gourmet_Food.csv'\n",
    "review_filepath = 'raw_data/Grocery_and_Gourmet_Food_5.json' \n",
    "metadata_filepath = 'raw_data/meta_Grocery_and_Gourmet_Food.json'\n",
    "\n",
    "raw_ratings, raw_reviews, raw_metadata = load_data(rating_filepath=rating_filepath, review_filepath=review_filepath, metadata_filepath=metadata_filepath)\n",
    "\n",
    "reviews_df, metadata_df = prepare_data(raw_ratings, raw_reviews, raw_metadata)\n",
    "\n",
    "# Save the new dataframes to later use. \n",
    "reviews_df.to_csv('data/reviews_df.csv',index=False)\n",
    "metadata_df.to_csv('data/metadata_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "The idea behind our investigation is to find features of high rated products and recommend to add the features to low rated products. However, if the products are too different like chocolate and apples it does not make sense to compare features for these products even if one has a high rating and the other a low rating. Therefore, we analyze the data by looking at the different product categories and explore the number of products, the number of ratings and variance in the average rating of the products. IT is important for our analysis that we have categories with both many products and many ratings. However it is also important that we have something to improve, meaning we need categories with some variances in the average rating of products. We will only be looking at the top 20 categories in the exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# lead data \n",
    "df = pd.read_csv('data/metadata_df.csv')\n",
    "\n",
    "# Number of products in each category\n",
    "def get_category(row, categories):\n",
    "    if row in categories:\n",
    "        return row\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# We will only look at the top 20 categories\n",
    "top = 20\n",
    "categories = df['category'].value_counts().sort_values(ascending=False).index[0:top].to_list()\n",
    "\n",
    "# Copy the dataframe\n",
    "df_category = df.copy(deep=True)\n",
    "\n",
    "# Return number of products in each category\n",
    "df_category['category'] = df_category['category'].apply(lambda row: get_category(row, categories))\n",
    "df_category = df_category[df_category['category'] != '']\n",
    "\n",
    "# Number of ratings in each category\n",
    "df_num_ratings = df[['category','num_ratings']].groupby(by=[\"category\"]).sum([\"num_ratings\"])\n",
    "df_num_ratings = df_num_ratings['num_ratings'].sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Plot of the number of productts in each category and the number of ratings in each category\n",
    "fig, ((ax1, ax2)) = plt.subplots(1,2)\n",
    "sns.countplot(x=\"category\", data=df_category, order=categories, ax=ax1)\n",
    "ax1.set_ylabel('Number of products')\n",
    "ax1.set_xticklabels(categories,rotation=90)\n",
    "sns.barplot(x=\"category\", y=\"num_ratings\", data=df_num_ratings[0:top], ax=ax2)\n",
    "ax2.set_ylabel('Number of ratings')\n",
    "ax2.set_xticklabels(df_num_ratings.loc[0:(top-1),'category'].to_list(),rotation=90)\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "# Plot with variance of average ratings in each category \n",
    "categories_union = list(set().union(categories,df_num_ratings.loc[0:top,'category'])) # list of categories shown in figure 1 and 2\n",
    "df_mean_avg_rating = df[df['category'].isin(categories_union)].groupby('category').median(['avg_rating']).sort_values(by='avg_rating',ascending=False)\n",
    "categories_union = df_mean_avg_rating.index.to_list()\n",
    "plt.figure(2)\n",
    "sns.boxplot(x = 'category', y = 'avg_rating', data = df[df['category'].isin(categories_union)], order = categories_union)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By investigating the plot with number of ratings and number of products we find \"Beverages\", \"Cooking & Baking\", \"Candy & Chocolate\" and \"Snack Foods\" are the categories with most in both. When we compare these categories with the boxplot showing the variance of the average rating, both \"Snack Foods\" and \"Candy & Chocolate\" have a decent spread. \"Beverages\" and \"Cooking & Baking\" almost have the same median and spread, but \"Beverages\" has both more products and ratings and we therefore only use \"Beverages\" as a category along with \"Candy & Chocolate\" and \"Snack Foods\". \n",
    "\n",
    "These three categories are then saved as csv file separetily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Select category \n",
    "category = 'Snack Foods'\n",
    "df_cat = df[df['category']==category]\n",
    "\n",
    "# Save dataframe for category \n",
    "df_cat.to_csv('data/'+category+'/df_'+category+'.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
